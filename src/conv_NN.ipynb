{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "yp825FIuDTwv",
    "outputId": "cb49f6cd-0771-4abb-9771-cc6eb6041476",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-vluFGFQDTwz",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "with open(\"MW.txt\") as data:\n",
    "    reader = csv.reader(data, delimiter='\\t')\n",
    "    d = list(reader)\n",
    "for i in d:\n",
    "    i[6]=[int(i) for i in  i[6].split(',')]\n",
    "    i[6]=i[6][0:441]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "VnWBQy5_DTw2",
    "outputId": "0001c7d1-c4e0-45c3-cdd4-c68d3c1103f7",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441\n",
      "['1', '1', 'MW', 'FP1', '1', '889', [83, 74, 65, 65, 66, 55, 43, 25, 18, 20, 26, 33, 41, 38, 28, 36, 55, 60, 56, 58, 72, 85, 76, 69, 74, 83, 86, 88, 97, 112, 114, 109, 99, 76, 54, 50, 66, 86, 97, 99, 96, 86, 82, 73, 69, 70, 70, 60, 65, 71, 69, 64, 57, 54, 56, 58, 50, 20, -20, -56, -74, -69, -57, -57, -60, -69, -75, -71, -59, -45, -24, 3, 13, 10, 8, 10, 5, 7, 8, -3, -22, -28, -20, 1, 3, -10, -18, -12, -19, -23, -25, -36, -45, -43, -37, -23, -4, 4, -2, -3, -3, -2, 5, 8, 7, 5, 16, 29, 34, 35, 36, 48, 68, 80, 80, 75, 68, 69, 77, 89, 105, 100, 80, 64, 56, 59, 64, 57, 49, 42, 48, 60, 75, 77, 70, 61, 45, 28, 24, 28, 29, 34, 40, 50, 42, 27, 16, 4, 1, 6, 12, 16, 20, 24, 34, 44, 54, 58, 53, 40, 24, 11, 4, -4, -14, -34, -56, -76, -77, -68, -53, -44, -38, -35, -30, -30, -30, -25, -6, 18, 29, 27, 23, 27, 41, 50, 51, 57, 57, 51, 55, 57, 58, 53, 37, 20, 9, 12, 29, 49, 49, 37, 28, 37, 57, 76, 83, 74, 68, 50, 25, 9, 13, 39, 71, 103, 121, 130, 132, 136, 146, 163, 184, 188, 171, 152, 152, 164, 166, 155, 139, 131, 133, 134, 137, 136, 122, 112, 109, 116, 125, 138, 139, 130, 116, 113, 123, 144, 162, 168, 165, 149, 124, 114, 114, 118, 61, 51, 48, 49, 43, 45, 53, 55, 39, 25, 26, 35, 41, 41, 37, 27, 21, 18, 22, 25, 13, -6, -14, -5, 10, 21, 11, 9, 7, 1, 7, 36, 59, 57, 33, 8, 4, 21, 41, 53, 48, 27, 9, 9, 20, 21, 17, 12, 9, 12, 25, 25, 12, 2, -4, -6, -6, 2, 3, -9, -21, -20, -12, 3, -8, -17, -13, -8, -9, -12, -19, -26, -36, -52, -61, -58, -49, -41, -37, -33, -12, 11, 8, -2, 5, 20, 26, 26, 18, 11, 20, 27, 29, 17, -1, -2, 5, 28, 52, 50, 28, 8, 7, 17, 9, -13, -37, -52, -57, -59, -56, -45, -34, -25, -24, -23, -23, -27, -24, -23, -34, -36, -33, -30, -34, -24, -51, -54, -50, -39, -23, -3, 11, 16, 25, 34, 33, 36, 38, 40, 35, 28, 27, 33, 39, 40, 40, 48, 53, 55, 59, 53, 44, 50, 41, 19, -6, -22, -41, -56, -72, -77, -82, -90, -103, -113, -117, -120, -123, -123, -130, -152, -161, -154, -153, -162, -173, -185, -189, -190, -189, -189, -180, -169, -177]]\n"
     ]
    }
   ],
   "source": [
    "j=1000\n",
    "for m in d:\n",
    "    if int(m[5])<j:\n",
    "        j=int(m[5])\n",
    "print(j)\n",
    "print(d[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i=0\n",
    "\n",
    "y=y.tolist()\n",
    "print(y.count('-1'))\n",
    "yl=[]\n",
    "while True:\n",
    "        try:\n",
    "            # Search for item in list from indexPos to the end of list\n",
    "            i = y.index('-1', i)\n",
    "            yl.append(i)\n",
    "            i += 1\n",
    "        except ValueError as e:\n",
    "            break\n",
    "\n",
    "\n",
    "yl.reverse()\n",
    "print(len(yl))\n",
    "for i in yl:\n",
    "    del y[i]\n",
    "    del x[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "LfeSDgj5DTw5",
    "outputId": "60cf37b3-cbf5-446f-9101-63f27769d7e2",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67635,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(67635, 441)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.DataFrame(d)\n",
    "X = dataset.iloc[:, 6].values\n",
    "y = dataset.iloc[:, 4].values\n",
    "x=[]\n",
    "\n",
    "for i in X:\n",
    "    x.append(i)\n",
    "\n",
    "    \n",
    "X = pd.DataFrame(x)\n",
    "y = np.array(y)\n",
    "print(y.shape)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "SHieAUs6DTw8",
    "outputId": "b6c6e715-db2d-40e2-ed12-36090b8ba023",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      38\n",
      "1      48\n",
      "2      51\n",
      "3      44\n",
      "4      48\n",
      "       ..\n",
      "436   -62\n",
      "437   -60\n",
      "438   -53\n",
      "439   -55\n",
      "440   -73\n",
      "Name: 0, Length: 441, dtype: int64\n",
      "0\n",
      "['-1' '0' '1' '2' '3' '4' '5' '6' '7' '8' '9']\n"
     ]
    }
   ],
   "source": [
    "print(X.T[0])\n",
    "print(y[0])\n",
    "print(np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "colab_type": "code",
    "id": "FFBRkpQwDTw_",
    "outputId": "4e0e2ad8-7442-4167-e4f4-cd9cf0a6b7db",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      38\n",
      "1      48\n",
      "2      51\n",
      "3      44\n",
      "4      48\n",
      "       ..\n",
      "436   -62\n",
      "437   -60\n",
      "438   -53\n",
      "439   -55\n",
      "440   -73\n",
      "Name: 0, Length: 441, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "436    0\n",
       "437    0\n",
       "438    0\n",
       "439    0\n",
       "440    0\n",
       "Length: 441, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.T[0])\n",
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In following cell class labels have been reassigned from -1 - 9 to 0 - 10 to make them compatible with cross entropy\n",
    "Label :     0 1 2 3 4 5 6 7 8 9 10\n",
    "prediction:-1 0 1 2 3 4 5 6 7 8 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "WkdBFB_hDTxC",
    "outputId": "f54a108a-414c-4f3c-eb6e-388a5dad9e8c",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47344,)\n",
      "(47344, 441, 1)\n",
      "(20291,)\n",
      "(20291, 441, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "y = [int(x)+1 for x in y]\n",
    "y=np.array(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "#y_test = np_utils.to_categorical(y_test)\n",
    "#y_train = np_utils.to_categorical(y_train)\n",
    "\n",
    "X_train=np.array(X_train)\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0],X_train.shape[1],1))\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "X_test = X_test.reshape((X_test.shape[0],X_test.shape[1],1))\n",
    "\n",
    "print(y_train.shape)\n",
    "print(X_train.shape)\n",
    "\n",
    "print(y_test.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "colab_type": "code",
    "id": "kuPpR5RLDTxG",
    "outputId": "5d4f1e8a-9722-4513-af30-0e3accfb2b42",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 431, 256)          3072      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 421, 128)          360576    \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 411, 64)           90176     \n",
      "_________________________________________________________________\n",
      "average_pooling1d_1 (Average (None, 205, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 205, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 199, 128)          57472     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 193, 128)          114816    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_2 (Average (None, 96, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12288)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              12583936  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 11)                1419      \n",
      "=================================================================\n",
      "Total params: 13,801,931\n",
      "Trainable params: 13,801,931\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=256, kernel_size=11, activation='relu', input_shape=(441, 1)))\n",
    "model.add(Conv1D(filters=128, kernel_size=11, activation='relu'))\n",
    "model.add(Conv1D(filters=64, kernel_size=11, activation='relu'))\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=128, kernel_size=7, activation='relu'))\n",
    "model.add(Conv1D(filters=128, kernel_size=7, activation='relu'))\n",
    "\n",
    "model.add(AveragePooling1D(pool_size=2))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(11, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy' , optimizer=keras.optimizers.Adam(learning_rate=0.00001), metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "#keras.optimizers.Adadelta(learning_rate=0.001, rho=0.95, epsilon=1e-07, name=\"Adadelta\", **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "i_MUqweXDTxJ",
    "outputId": "75146b3d-776e-4ec2-ee89-9c9c6d358f2c",
    "pycharm": {
     "is_executing": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "47344/47344 [==============================] - 24s 516us/step - loss: 2.3949 - accuracy: 0.1692\n",
      "Epoch 2/50\n",
      "47344/47344 [==============================] - 22s 470us/step - loss: 2.2502 - accuracy: 0.1879\n",
      "Epoch 3/50\n",
      "47344/47344 [==============================] - 22s 471us/step - loss: 2.1974 - accuracy: 0.2068\n",
      "Epoch 4/50\n",
      "47344/47344 [==============================] - 22s 474us/step - loss: 2.1601 - accuracy: 0.2192\n",
      "Epoch 5/50\n",
      "47344/47344 [==============================] - 22s 475us/step - loss: 2.1367 - accuracy: 0.2277\n",
      "Epoch 6/50\n",
      "47344/47344 [==============================] - 23s 477us/step - loss: 2.1210 - accuracy: 0.2302\n",
      "Epoch 7/50\n",
      "47344/47344 [==============================] - 23s 479us/step - loss: 2.1052 - accuracy: 0.2373\n",
      "Epoch 8/50\n",
      "47344/47344 [==============================] - 23s 480us/step - loss: 2.0943 - accuracy: 0.2361\n",
      "Epoch 9/50\n",
      "47344/47344 [==============================] - 23s 481us/step - loss: 2.0857 - accuracy: 0.2386\n",
      "Epoch 10/50\n",
      "47344/47344 [==============================] - 23s 482us/step - loss: 2.0768 - accuracy: 0.2410\n",
      "Epoch 11/50\n",
      "47344/47344 [==============================] - 23s 483us/step - loss: 2.0723 - accuracy: 0.2410\n",
      "Epoch 12/50\n",
      "47344/47344 [==============================] - 23s 491us/step - loss: 2.0653 - accuracy: 0.2432\n",
      "Epoch 13/50\n",
      "47344/47344 [==============================] - 22s 454us/step - loss: 2.0590 - accuracy: 0.2431\n",
      "Epoch 14/50\n",
      "47344/47344 [==============================] - 24s 504us/step - loss: 2.0535 - accuracy: 0.2460\n",
      "Epoch 15/50\n",
      "47344/47344 [==============================] - 24s 508us/step - loss: 2.0493 - accuracy: 0.2457\n",
      "Epoch 16/50\n",
      "47344/47344 [==============================] - 24s 507us/step - loss: 2.0467 - accuracy: 0.2478\n",
      "Epoch 17/50\n",
      "47344/47344 [==============================] - 24s 503us/step - loss: 2.0402 - accuracy: 0.2494\n",
      "Epoch 18/50\n",
      "47344/47344 [==============================] - 24s 504us/step - loss: 2.0366 - accuracy: 0.2502\n",
      "Epoch 19/50\n",
      "47344/47344 [==============================] - 24s 508us/step - loss: 2.0325 - accuracy: 0.2506\n",
      "Epoch 20/50\n",
      "47344/47344 [==============================] - 24s 504us/step - loss: 2.0284 - accuracy: 0.2524\n",
      "Epoch 21/50\n",
      "47344/47344 [==============================] - 24s 502us/step - loss: 2.0261 - accuracy: 0.2517\n",
      "Epoch 22/50\n",
      "47344/47344 [==============================] - 24s 502us/step - loss: 2.0229 - accuracy: 0.2526\n",
      "Epoch 23/50\n",
      "47344/47344 [==============================] - 24s 502us/step - loss: 2.0202 - accuracy: 0.2572\n",
      "Epoch 24/50\n",
      "47344/47344 [==============================] - 24s 502us/step - loss: 2.0166 - accuracy: 0.2578\n",
      "Epoch 25/50\n",
      "47344/47344 [==============================] - 24s 502us/step - loss: 2.0107 - accuracy: 0.2594\n",
      "Epoch 26/50\n",
      "47344/47344 [==============================] - 24s 502us/step - loss: 2.0085 - accuracy: 0.2598\n",
      "Epoch 27/50\n",
      "47344/47344 [==============================] - 24s 502us/step - loss: 2.0048 - accuracy: 0.2618\n",
      "Epoch 28/50\n",
      "47344/47344 [==============================] - 24s 502us/step - loss: 2.0043 - accuracy: 0.2638\n",
      "Epoch 29/50\n",
      "47344/47344 [==============================] - 24s 502us/step - loss: 2.0004 - accuracy: 0.2640\n",
      "Epoch 30/50\n",
      "47344/47344 [==============================] - 24s 503us/step - loss: 1.9965 - accuracy: 0.2647\n",
      "Epoch 31/50\n",
      "47344/47344 [==============================] - 24s 502us/step - loss: 1.9931 - accuracy: 0.2683\n",
      "Epoch 32/50\n",
      "47344/47344 [==============================] - 24s 501us/step - loss: 1.9908 - accuracy: 0.2703\n",
      "Epoch 33/50\n",
      "47344/47344 [==============================] - 25s 521us/step - loss: 1.9862 - accuracy: 0.2727\n",
      "Epoch 34/50\n",
      "47344/47344 [==============================] - 24s 497us/step - loss: 1.9841 - accuracy: 0.2726\n",
      "Epoch 35/50\n",
      "47344/47344 [==============================] - 24s 517us/step - loss: 1.9836 - accuracy: 0.2741\n",
      "Epoch 36/50\n",
      "47344/47344 [==============================] - 24s 509us/step - loss: 1.9787 - accuracy: 0.2762\n",
      "Epoch 37/50\n",
      "47344/47344 [==============================] - 24s 509us/step - loss: 1.9742 - accuracy: 0.2777\n",
      "Epoch 38/50\n",
      "47344/47344 [==============================] - 24s 508us/step - loss: 1.9727 - accuracy: 0.2805\n",
      "Epoch 39/50\n",
      "47344/47344 [==============================] - 24s 508us/step - loss: 1.9662 - accuracy: 0.2836\n",
      "Epoch 40/50\n",
      "47344/47344 [==============================] - 24s 508us/step - loss: 1.9633 - accuracy: 0.2830\n",
      "Epoch 41/50\n",
      "47344/47344 [==============================] - 24s 508us/step - loss: 1.9613 - accuracy: 0.2846\n",
      "Epoch 42/50\n",
      "47344/47344 [==============================] - 24s 508us/step - loss: 1.9582 - accuracy: 0.2866\n",
      "Epoch 43/50\n",
      "47344/47344 [==============================] - 24s 510us/step - loss: 1.9542 - accuracy: 0.2886\n",
      "Epoch 44/50\n",
      "47344/47344 [==============================] - 24s 509us/step - loss: 1.9528 - accuracy: 0.2873\n",
      "Epoch 45/50\n",
      "47344/47344 [==============================] - 24s 511us/step - loss: 1.9491 - accuracy: 0.2894\n",
      "Epoch 46/50\n",
      "47344/47344 [==============================] - 25s 518us/step - loss: 1.9462 - accuracy: 0.2931\n",
      "Epoch 47/50\n",
      "47344/47344 [==============================] - 24s 517us/step - loss: 1.9449 - accuracy: 0.2925\n",
      "Epoch 48/50\n",
      "47344/47344 [==============================] - 25s 538us/step - loss: 1.9402 - accuracy: 0.2949\n",
      "Epoch 49/50\n",
      "47344/47344 [==============================] - 25s 539us/step - loss: 1.9340 - accuracy: 0.2972\n",
      "Epoch 50/50\n",
      "47344/47344 [==============================] - 24s 514us/step - loss: 1.9325 - accuracy: 0.2981\n",
      "Test accuracy :  0.26844415068626404\n"
     ]
    }
   ],
   "source": [
    "# fit network\n",
    "model.fit(X_train, y_train, epochs = 50, batch_size = 256)\n",
    "# evaluate model\n",
    "_, accuracy = model.evaluate(X_test, y_test, batch_size=256, verbose=0)\n",
    "print (\"Test accuracy : \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aCidYHeqgZTj",
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 7 7 ... 5 1 2]\n",
      "---------------------\n",
      "[ 1  3 10 ...  6  3  6]\n"
     ]
    }
   ],
   "source": [
    "ynew = model.predict_classes(X_test)\n",
    "print(ynew)\n",
    "print(\"---------------------\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Category    TP    FP     TN    FN\n",
      "0         0  3627  1276  15146   242\n",
      "1         1   231  1760  16880  1420\n",
      "2         2   620  3911  14766   994\n",
      "3         3    63   509  18132  1587\n",
      "4         4   124  1157  17531  1479\n",
      "5         5   157  1050  17653  1431\n",
      "6         6    91   752  17883  1565\n",
      "7         7   377  3076  15560  1278\n",
      "8         8    71   637  17948  1635\n",
      "9         9    11   124  18497  1659\n",
      "10       10    75   592  18070  1554 \n",
      "\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "[[3627   33   89    9   24   14   10   35   11    2   15]\n",
      " [ 125  231  450   49  105  139   83  333   67   12   57]\n",
      " [ 124  188  620   41  119   50   98  252   43   11   68]\n",
      " [ 123  192  428   63  134  130   75  344   80   15   66]\n",
      " [ 138  180  473   60  124   90   82  311   72   13   60]\n",
      " [ 139  176  303   70  124  157   66  391   85   15   62]\n",
      " [ 120  186  513   47  163   95   91  310   63   17   51]\n",
      " [ 129  201  398   55  118  131   75  377   71   17   83]\n",
      " [ 125  203  390   61  128  163   90  397   71   12   66]\n",
      " [ 134  198  462   66  129  101   90  356   59   11   64]\n",
      " [ 119  203  405   51  113  137   83  347   86   10   75]]\n",
      "Accuracy:  0.2684441377950816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "z=0\n",
    "acc=0\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "def plot_confusion_matrix(y_true, y_pred, classes, normalize=False, title=None, cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "def perf_measure(y_actual, y_hat):\n",
    "    TP, FP, TN, FN = 0, 0, 0, 0\n",
    "    for i in range(len(y_hat)): \n",
    "        if y_actual[i]==y_hat[i]==1:\n",
    "            TP += 1\n",
    "        elif y_hat[i]==1 and y_actual[i]!=y_hat[i]:\n",
    "            FP += 1\n",
    "        elif y_actual[i]==y_hat[i]==0:\n",
    "            TN += 1\n",
    "        elif y_hat[i]==0 and y_actual[i]!=y_hat[i]:\n",
    "            FN += 1\n",
    "\n",
    "    return [TP, FP, TN, FN]\n",
    "\n",
    "def display_results(test_labels, categories, predicted_categories):\n",
    "    df = pd.DataFrame(columns= ['Category']+list(categories))\n",
    "\n",
    "    cols = ['Category']+['TP', 'FP', 'TN', 'FN']\n",
    "    df = pd.DataFrame(columns= cols)\n",
    "    for el in categories:\n",
    "        temp_y_test = (test_labels == el).astype(int)\n",
    "        temp_preds = (predicted_categories == el).astype(int)\n",
    "        row = [el]+ perf_measure(temp_y_test, temp_preds)\n",
    "        df = df.append(pd.Series(row, index=cols), ignore_index=True)\n",
    "    print(df, '\\n\\n')\n",
    "\n",
    "    for i in range(len(categories)):\n",
    "        test_labels[test_labels==categories[i]] = i\n",
    "        predicted_categories[predicted_categories==categories[i]] = i\n",
    "    test_labels, predicted_categories = test_labels.astype(int), predicted_categories.astype(int)\n",
    "\n",
    "    class_names=np.array(categories)\n",
    "    plot_confusion_matrix(test_labels, predicted_categories, classes=class_names)\n",
    "    fig = plt.gcf()\n",
    "    fig.show()\n",
    "    \n",
    "    acc = accuracy_score(y_pred=predicted_categories, y_true=test_labels) #you need to put your own array names here\n",
    "    print('Accuracy: ', acc)\n",
    "    \n",
    "    return\n",
    "\n",
    "display_results(y_test, [0,1,2,3,4,5,6,7,8,9,10], ynew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 441, 1)            4         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 441, 128)          1536      \n",
      "_________________________________________________________________\n",
      "average_pooling1d_3 (Average (None, 110, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 110, 128)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 110, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 110, 256)          360704    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_4 (Average (None, 55, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 55, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 14080)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                140810    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 11)                121       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 11)                132       \n",
      "=================================================================\n",
      "Total params: 503,819\n",
      "Trainable params: 503,561\n",
      "Non-trainable params: 258\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.BatchNormalization(input_shape=np.shape(X_train)[1:]))\n",
    "model.add(keras.layers.Conv1D(128, 11, padding='same', activation='tanh'))\n",
    "model.add(keras.layers.AveragePooling1D(pool_size=(4)))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "\n",
    "\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Conv1D(256, 11, padding='same', activation='tanh'))\n",
    "model.add(keras.layers.AveragePooling1D(pool_size=(2)))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.Conv1D(128, 8, padding='same', activation='elu'))\n",
    "# model.add(tf.keras.layers.AveragePooling1D(pool_size=(4)))\n",
    "# model.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(10))\n",
    "model.add(keras.layers.Activation('elu'))\n",
    "model.add(keras.layers.Dense(11))\n",
    "model.add(keras.layers.Dense(11, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy' , optimizer='Adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "conv_NN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
